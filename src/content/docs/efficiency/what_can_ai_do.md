---
title: What Can AI Do?
description: Learn what can AI do the best and when AI falls short.
---

> Learn what can AI do the best and when AI falls short.

In this page, you are going to learn about the capabilities and limitations of AI, especially in academic settings. Let’s explore where AI excels, where it disappoints, and how different models differ in their thinking. After finishing this page, you will know when AI would help you and when AI would drag down your productivity.

---

## 1. What AI Does Best

By AI, this site is referencing to LLM (Large Language Model), the most common type of AI nowadays that is being used behind ChatGPT, Google Gemini, Claude, and more.

So, when does it work the best?

### a. Writing & Content Generation

AI can draft essays (you have to be careful with this though, check the Ethics section), summaries, flashcards, and study notes almost instantly. Whether you're restating definitions or rewriting your thoughts, it's fast and fluid.

**Example:**
You ask: _“Summarize the causes of the Civil War in two paragraphs.”_
AI delivers a concise and coherent summary—perfect as a study starting point.

### b. Brainstorming & Outlining

AI is excellent at idea generation. Need essay topics, project themes, or bullet-point plans? It can produce those in seconds.

**Example:**
You ask _“Give me five creative project ideas for environmental science.”_
AI quickly lists ideas like “urban microclimate mapping with DIY sensors,” or “bioplastics from kitchen waste.”

### c. Reasoned Problem-Solving (with techniques)

When guided with the right prompts—like “Let’s think step by step”—AI can tackle multi-step problems in math, logic, or coding with logical precision. Or you can instead use a **Reasoning Model**, which automatically guides itself through steps in solving a problem. We will talk about it later.

**Example:**
_“If the cafeteria had 23 apples, used 20, then bought 6, how many remain? Let’s think step by step.”_
AI breaks it down: 23 − 20 = 3, then 3 + 6 = 9.

---

## 2. Where AI Falls Short

### a. Hallucinations & Confabulations

AI sometimes fabricates information—invented dates, fake citations, or baseless quotes. Always double-check facts.

### b. No Genuine Understanding

AI recognizes patterns, not meaning. It can mimic reasoning but doesn't "understand" concepts like a human does.

### c. Knowledge Cutoffs & Outdated Info

Unless connected to real-time sources, AI only "knows" what it's been trained on.

### d. Encouraging Over-Reliance

Studies show students often engage less cognitively when AI provides instant solutions. Without effort, critical thinking can suffer.

### e. Complex Challenges Still Tough

Even advanced AI models falter on highly complex reasoning tasks—especially when escape routes like hallucination arise.

---

## 3. Language Models vs. Reasoning Models: What’s the Difference?

If you are using ChatGPT, you are able to choose from GPT-5 Instant (Language Model) and GPT-5 Thinking (Reasoning Model) as of September 2025.

What are the difference between Language Models and Reasoning Models, and when should you use each? Let's find out.

### Language Models (LLMs)

- **What they are:** Models trained to predict and produce text based on patterns. It is the classic type of large language models.

- **Best at:** Creative writing, summarizing, translating, and quick conversation.

- **Trade offs:** It does not go through thorough reasoning processes when responding to user's question. When dealing with complicated or STEM heavy questions, it might not be capable of giving the best response.

---

### Reasoning Models (RLMs)

- **What they are:** LLMs fine-tuned or architected to generate structured, multi-step reasoning.They produce intermediate “private” reasoning steps, not visible to the user, to arrive at more reliable answers.

- **Best at:** Solving STEM related problems or answer complicated question that requires "thinking".

- **Trade-offs:** It usually takes much longer for Reasoning Models to repond a problem as it has to go through the reasoning process before giving out the response. And it might potentially overthink when dealing with simple, straightaway problems.

---

## Table: When to use what AI?

| Task                                  | Use AI? | Use Reasoning Model?         | Why It Works                                                                    |
| ------------------------------------- | -------- | ---------------------------- | ------------------------------------------------------------------------------- |
| Drafting essay topics or intros       | Yes (Responsibly)      | Only if the topic is complicated or requires "thinking" | Quick idea generation is perfect for LLMs. Reasoning adds cost without benefit. |
| Tackling a multi-step algebra problem | Possible | Yes                          | Reasoning models help trace logic and avoid simple mistakes.                    |
| Summarizing a reading book chapter    | Yes (Responsibly)      | No                           | Fast and fluent—perfect for LLMs.                                               |
| Debugging a coding logic error        | Possible | Yes                          | Complex logic demands reasoning steps over fluent output.                       |

---

## Summary

- **Know your AI’s strengths:** Use it to generate, brainstorm, and summarize.
- **Guard against its limitations:** Always cross-check facts, especially with hallucination risk.
- **Think critically:** Don’t substitute understanding with convenience.
- **Choose the right AI for the task:** Use LLMs for creative tasks, reasoning models for complex logic.
- **Maintain your learning:** Use AI as a tool to support—not replace—your thinking.
